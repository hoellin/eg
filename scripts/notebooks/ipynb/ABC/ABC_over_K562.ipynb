{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABC over K562"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use this notebook?\n",
    "First, make a copy of [this notebook](http://genoweb.toulouse.inra.fr/~thoellinger/stable/ipynb/ABC/ABC_generic.ipynb) on your computer / cluster.\n",
    "\n",
    "Then, to use this notebook, one should only have to carefully modify the content of the \"Set working directory\" section, then to execute the notebook cell by cell, in the correct order. After execution of each cell, remember to check for errors before executing the next one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can use the following to switch notebook theme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# night theme\n",
    "#!jt -t monokai -f fira -fs 10 -nf ptsans -nfs 11 -N -kl -cursw 2 -cursc r -cellw 95% -T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard theme\n",
    "#!jt -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path #Or see https://stackoverflow.com/a/82852 for an object-oriented approach\n",
    "from IPython.core.magic import register_line_cell_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_user = \"tristan.hoellinger@inserm.fr\" # slurm notifications\n",
    "version = \"hg19\" # used only in the current cell to compute some paths \n",
    "cell_type = \"k562\" # used all along the notebook\n",
    "specie = \"homo_sapiens/\"+version+\"/\" # used only in the current cell to compute some paths \n",
    "\n",
    "# Where to store run-specific references, scripts, intermediate files, predictions, etc\n",
    "work_dir = \"/work2/project/regenet/workspace/thoellinger/ABC-Enhancer-Gene-Prediction/new_K562/\"\n",
    "\n",
    "scripts = work_dir+\"hi_slurm/\" # where to store scripts specific to this run\n",
    "results_dir = \"/work2/project/regenet/results/\" # used to compute paths where data for this cell type is\n",
    "                                                # stored / will be downloaded\n",
    "dnase_dir = results_dir+\"dnaseseq/\"+specie+cell_type+'/'\n",
    "chipseq_dir = results_dir+\"chipseq/h3k27ac/\"+specie+cell_type+'/'\n",
    "expression_dir = results_dir+\"rnaseq/\"+specie+cell_type+'/'\n",
    "blacklist_dir = results_dir+\"multi/\"+specie # where the ENCODE blacklist is (going to be) stored\n",
    "\n",
    "blacklist = blacklist_dir+version+\"-blacklist.v2.bed\" # need not exist yet\n",
    "\n",
    "# Gene annotation in the gtf format and gene name / gene id table (1st column id, 2nd column name)\n",
    "gene_annotation = \"/work2/project/fragencode/data/species.bk/homo_sapiens/hg19.gencv19/homo_sapiens.gtf\"\n",
    "gnid_gname = \"/work2/project/fragencode/data/species.bk/homo_sapiens/hg19.gencv19/homo_sapiens.gnid.gnname.tsv\"\n",
    "\n",
    "# Accessions for the current run. Just put accession numbers here, no need to download these accessions \"by hand\".\n",
    "dnase_rep1 = \"ENCFF001DOX\" # see https://www.encodeproject.org/files/ENCFF001DOX/\n",
    "                           # => \"Original file name hg19/wgEncodeUwDnase/wgEncodeUwDnaseK562AlnRep1.bam\"\n",
    "                           # (actually wgEncodeUwDnaseK562AlnRep1.bam is the name fiven in Supplementary Table 4)\n",
    "dnase_rep2 = \"wgEncodeUwDnaseK562AlnRep2\" # well we found new accession corresponding to wgEncodeUwDnaseK562AlnRep1.bam,\n",
    "                # ENCFF001DOX (archived), but not to wgEncodeUwDnaseK562AlnRep2.bam.\n",
    "                # Fortunately we found the file here: http://hgdownload.cse.ucsc.edu/goldenpath/hg19/encodeDCC/wgEncodeUwDnase/\n",
    "h3k27_rep1 = \"ENCFF384ZZM\" # exp ENCSR000AKP\n",
    "h3k27_rep2 = \"ENCFF070PWH\" # exp ENCSR000AKP\n",
    "rnaseq_rep1 = \"ENCFF172GIN\" # exp ENCSR000CPH\n",
    "rnaseq_rep2 = \"ENCFF768TKT\" # exp ENCSR000CPH\n",
    "\n",
    "# Where to download the blacklist. Will not be used unless blacklist not found yet.\n",
    "blacklist_link = \"https://github.com/Boyle-Lab/Blacklist/raw/master/lists/hg19-blacklist.v2.bed.gz\"\n",
    "\n",
    "dnase_file_rep1 = dnase_dir+dnase_rep1+\".bam\" # you shall not change this\n",
    "dnase_file_rep2 = dnase_dir+dnase_rep2+\".bam\"  # you shall not change this\n",
    "h3k27_file_rep1 = chipseq_dir+h3k27_rep1+\".bam\"  # you shall not change this\n",
    "h3k27_file_rep2 = chipseq_dir+h3k27_rep2+\".bam\"  # you shall not change this\n",
    "rnaseq_file_rep1 = expression_dir+rnaseq_rep1+\".tsv\"  # you shall not change this\n",
    "rnaseq_file_rep2 = expression_dir+rnaseq_rep2+\".tsv\"  # you shall not change this\n",
    "\n",
    "reference_dir = work_dir+\"reference/\" # you shall not change this\n",
    "annotations_dir = reference_dir+\"gene_annotation/\" # you shall not change this\n",
    "peaks = work_dir+\"ABC_output/Peaks/\" # you shall not change this\n",
    "neighborhoods = work_dir+\"ABC_output/Neighborhoods/\" # you shall not change this\n",
    "predictions = work_dir+\"ABC_output/Predictions/\" # you shall not change this\n",
    "\n",
    "light_annotation = annotations_dir+\"gene_ids.bed\" # you shall not change this\n",
    "\n",
    "# Ubiquitously expressed genes (gene names). If provided, `ubiquitously_expressed_genes` will be\n",
    "# automatically generated with gene ids instead of gene names. If not (left empty), \n",
    "# `ubiquitously_expressed_genes` must be provided.\n",
    "ubiquitous_gene_names = work_dir+\"../reference/UbiquitouslyExpressedGenesHG19.txt\"\n",
    "# Ubiquitously expressed genes (gene ids). Please provide either `ubiquitously_expressed_genes` or\n",
    "# `ubiquitous_gene_names`\n",
    "ubiquitously_expressed_genes = reference_dir+\"UbiquitouslyExpressedGenes_ids.txt\" # need not exist\n",
    "\n",
    "compute_mean_expression = work_dir+\"../compute_mean_expression.awk\"\n",
    "# compute_mean_expression.awk computes an expression table (<gene id> <expression>) taking the mean\n",
    "# TPM expression found in the 2 input polyA+ RNA-seq tsv.\n",
    "\n",
    "make_candidate_regions = work_dir+\"../src/makeCandidateRegions.py\"\n",
    "run_neighborhoods = work_dir+\"../src/run.neighborhoods.py\"\n",
    "predict = work_dir+\"../src/predict.py\"\n",
    "\n",
    "genome_file = reference_dir+\"chr_sizes\" # shall not exist yet\n",
    "\n",
    "gene_expression_table = reference_dir+\"expression/\"+cell_type+\".\"+rnaseq_rep1+\"_\"+rnaseq_rep2+\".mean.TPM.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(reference_dir):\n",
    "    !mkdir $reference_dir\n",
    "if not os.path.isdir(scripts):\n",
    "    !mkdir $scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One may only change what is between quotes here\n",
    "slurm_1_1 = scripts+\"step1.1.sh\"\n",
    "slurm_1_2 = scripts+\"step1.2.sh\"\n",
    "slurm_1_3 = scripts+\"step1.3.sh\"\n",
    "slurm_2 = scripts+\"step2.sh\"\n",
    "slurm_3 = scripts+\"step3.sh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRiFF_dir = \"/work2/project/regenet/workspace/thoellinger/CRISPRi_FlowFISH/k562/\"\n",
    "all_criff = CRiFF_dir+\"3863.fulco.bedpe.sorted\"\n",
    "\n",
    "candidateRegions = reference_dir+\"candidateRegions.bed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chromatin accessibility (DNase-seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile(dnase_file_rep1):\n",
    "    !wget https://www.encodeproject.org/files/$dnase_rep1/@@download/$dnase_rep1$\".bam\" -P $dnase_dir\n",
    "            \n",
    "if not os.path.isfile(dnase_file_rep2):\n",
    "    !wget http://hgdownload.cse.ucsc.edu/goldenpath/hg19/encodeDCC/wgEncodeUwDnase/$dnase_rep2$\".bam\" -P $dnase_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blacklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(blacklist):\n",
    "    !wget $blacklist_link -P $blacklist_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histone mark H3K27ac ChIP-seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile(h3k27_file_rep1):\n",
    "    !wget https://www.encodeproject.org/files/$h3k27_rep1/@@download/$h3k27_rep1$\".bam\" -P $chipseq_dir\n",
    "            \n",
    "if not os.path.isfile(h3k27_file_rep2):\n",
    "    !wget https://www.encodeproject.org/files/$h3k27_rep2/@@download/$h3k27_rep2$\".bam\" -P $chipseq_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gene expression (polyA+ RNA-seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(rnaseq_file_rep1):\n",
    "    !wget https://www.encodeproject.org/files/$rnaseq_rep1/@@download/$rnaseq_file_rep1 -P $expression_dir\n",
    "            \n",
    "if not os.path.isfile(rnaseq_file_rep2):\n",
    "    !wget https://www.encodeproject.org/files/$rnaseq_rep2/@@download/$rnaseq_file_rep2 -P $expression_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ubiquitously expressed genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$gnid_gname\" \"$ubiquitous_gene_names\" \"$ubiquitously_expressed_genes\"\n",
    "if [[ -f $2 ]] && [[ ! -f $3 ]]; then\n",
    "    awk 'BEGIN{sep=\"\\t\"} NR==FNR {id[$2]=$1; next} id[$1] {print id[$1]}' $1 $2 > $3\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genome file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$work_dir\" \"$dnase_file_rep1\" \"$genome_file\"\n",
    "CONDA_BASE=$(conda info --base) && source $CONDA_BASE/etc/profile.d/conda.sh\n",
    "conda activate base && module load bioinfo/samtools-1.9\n",
    "samtools view -H $2 | grep SQ | cut -f 2,3 |cut -c 4- |awk 'BEGIN{FS=\"\\t\"} {split($2,locus,\":\"); if($1 ~ /^(chr)([0-9]{1,2}$)|(M$)|(X$)|(Y$)/){print($1\"\\t\"locus[2])}}' > $3\n",
    "awk '{print $1\"\\t\"0\"\\t\"$2}' $3 > $3\".bed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reprocessing\n",
    "\n",
    "### Create expression table\n",
    "\n",
    "We use `compute_mean_expression.awk` to take as the reference TPM value, the mean value for the 2 replicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$compute_mean_expression\" \"$reference_dir\" \"$rnaseq_file_rep1\" \"$rnaseq_file_rep2\" \"$cell_type\" \"$rnaseq_rep1\" \"$rnaseq_rep2\"\n",
    "if [[ ! -d $2\"expression/\" ]]; then mkdir $2\"expression/\"; fi\n",
    "awk -f $1 $3 $4 > $2\"expression/\"$5\".\"$6\"_\"$7\".mean.TPM.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter gene annotation\n",
    "\n",
    "We keep genes only, and `gene_ids.bed` must fit following format:\n",
    "> ```bash\n",
    "> chrX\t99883667\t99894988\tENSG00000000003.10\t0\t-\n",
    "> chrX\t99839799\t99854882\tENSG00000000005.5\t0\t+\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$work_dir\" \"$genome_file\" \"$annotations_dir\" \"$gene_annotation\" \"$light_annotation\"\n",
    "if [[ ! -d $3 ]]; then mkdir $3; fi\n",
    "CONDA_BASE=$(conda info --base) && source $CONDA_BASE/etc/profile.d/conda.sh\n",
    "conda activate base && module load bioinfo/bedtools-2.27.1\n",
    "awk '{if(NR==FNR){!genome[$1]++; next}; if(genome[$1]){if($3 ~ /(^gene$)/){print $1\"\\t\"$4\"\\t\"$5\"\\t\"substr($10,2,length($10)-3)\"\\t\"0\"\\t\"$7}}}' $2 $4 | bedtools sort -g $2 -i stdin > $5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the ABC model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: define candidate elements\n",
    "\n",
    "#### Call peaks with `macs2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate $slurm_1_1\n",
    "#!/bin/sh                                                                                                                                                                                                                    \n",
    "# dependencies: python2\n",
    "macs2 callpeak \\\n",
    "-t {dnase_file_rep1} {dnase_file_rep2} \\\n",
    "-n {dnase_rep1}_{dnase_rep2}.macs2 \\\n",
    "-f BAM \\\n",
    "-g hs \\\n",
    "-p .1 \\\n",
    "--call-summits \\\n",
    "--outdir {peaks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 23346597\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$work_dir\" \"$slurm_1_1\" \"$mail_user\"\n",
    "CONDA_BASE=$(conda info --base) && source $CONDA_BASE/etc/profile.d/conda.sh\n",
    "conda activate base && conda activate abcmodel\n",
    "module load bioinfo/samtools-1.9 bioinfo/bedtools-2.27.1 bioinfo/tabix-0.2.5 bioinfo/juicer-1.5.6\n",
    "conda activate py2 && module load system/Python-2.7.2\n",
    "sbatch --mem=4G --cpus-per-task=1 -J step1.1 --mail-user=$3 --mail-type=END,FAIL --workdir=$1 --export=ALL -p workq $2\n",
    "conda deactivate && module unload system/Python-2.7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: 23346597\r\n",
      "Cluster: genobull\r\n",
      "User/Group: thoellinger/U1220\r\n",
      "State: COMPLETED (exit code 0)\r\n",
      "Cores: 1\r\n",
      "CPU Utilized: 00:16:55\r\n",
      "CPU Efficiency: 98.16% of 00:17:14 core-walltime\r\n",
      "Job Wall-clock time: 00:17:14\r\n",
      "Memory Utilized: 759.34 MB\r\n",
      "Memory Efficiency: 18.54% of 4.00 GB\r\n"
     ]
    }
   ],
   "source": [
    "!seff 23346597"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use ABC `makeCandidateRegions.py` to define candidate regions\n",
    "\n",
    "As there are peaks over many kinds of scaffolds listed in the `.narrowPeak` and `.xls` output files, we modify them keep only chromosomes only (otherwise `bedtools sort` below would not work). **But we have to keep in mind that the `.r` will still corresponds to DNase peaks over all scaffolds**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$peaks\" \"$dnase_rep1\" \"$dnase_rep2\"\n",
    "awk '$1 ~ /^(chr)([0-9]{1,2}$)|(M$)|(X$)|(Y$)/ {print $0}' $1$2\"_\"$3\".macs2_peaks.narrowPeak\" > $1/$2\"_\"$3\".chromosomes_only.macs2_peaks.narrowPeak\"\n",
    "awk 'NR <= 28 || $1 ~ /^(chr)([0-9]{1,2}$)|(M$)|(X$)|(Y$)/ {print $0}' $1$2\"_\"$3\".macs2_peaks.xls\" > $1$2\"_\"$3\".chromosomes_only.macs2_peaks.xls\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we sort the result (note that it seems quite tricky to use `srun` from a notebook as we first need to export environment variables - maybe there is another way but as for now I could not find better):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "srun: job 23347039 queued and waiting for resources\n",
      "srun: job 23347039 has been allocated resources\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$peaks\" \"$dnase_rep1\" \"$dnase_rep2\" \"$genome_file\"\n",
    "export V1=$1 V2=$2 V3=$3 V4=$4\n",
    "CONDA_BASE=$(conda info --base) && source $CONDA_BASE/etc/profile.d/conda.sh\n",
    "conda activate base && conda activate abcmodel\n",
    "module load bioinfo/bedtools-2.27.1\n",
    "srun bash\n",
    "bedtools sort -faidx $V4 -i $V1$V2\"_\"$V3\".chromosomes_only.macs2_peaks.narrowPeak\" > $V1$V2\"_\"$V3\".macs2_peaks.narrowPeak.sorted\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as `work_dir ../src/makeCandidateRegions.py` does not support multiple `bam` inputs, we concatenate the bam of the 2 replicates.  Indeed, `makeCandidateRegions.py` will use the bam input to count DNase reads on each peak of the`.macs2_peaks.narrowPeak.sorted` output found with `macs2`.\n",
    "\n",
    "(WARNING: depending on the size of the input bam, which is much variable, the execution on 1 thread only can take from a few minutes to several hours, so better use at least 8 threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_threads = 8 #we recommend using at least 8 cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate $slurm_1_2\n",
    "#!/bin/sh\n",
    "# dependencies: bioinfo/samtools-1.9 bioinfo/bedtools-2.27.1\n",
    "\n",
    "if [[ ! -f {dnase_dir}{dnase_rep1}_{dnase_rep2}.bam ]]\n",
    "then\n",
    "    if [[ ! -f {dnase_dir}{dnase_rep1}_{dnase_rep2}.sam ]]\n",
    "    then\n",
    "        samtools view -@ {n_threads} -h {dnase_file_rep1} > {dnase_dir}{dnase_rep1}_{dnase_rep2}.sam\n",
    "        samtools view -@ {n_threads} {dnase_file_rep2} >> {dnase_dir}{dnase_rep1}_{dnase_rep2}.sam\n",
    "        samtools view -@ {n_threads} -S -b {dnase_dir}{dnase_rep1}_{dnase_rep2}.sam > {dnase_dir}{dnase_rep1}_{dnase_rep2}.bam\n",
    "        rm {dnase_dir}{dnase_rep1}_{dnase_rep2}.sam\n",
    "    else\n",
    "        samtools view -@ {n_threads} -S -b {dnase_dir}{dnase_rep1}_{dnase_rep2}.sam > {dnase_dir}{dnase_rep1}_{dnase_rep2}.bam\n",
    "    fi\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 23347154\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$work_dir\" \"$slurm_1_2\" \"$mail_user\"\n",
    "CONDA_BASE=$(conda info --base) && source $CONDA_BASE/etc/profile.d/conda.sh\n",
    "conda activate base && conda activate abcmodel\n",
    "module load bioinfo/samtools-1.9\n",
    "sbatch --mem=2G --cpus-per-task=8 -J step1.2 --mail-user=$3 --mail-type=END,FAIL --workdir=$1 --export=ALL -p workq $2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: 23347154\r\n",
      "Cluster: genobull\r\n",
      "User/Group: thoellinger/U1220\r\n",
      "State: COMPLETED (exit code 0)\r\n",
      "Nodes: 1\r\n",
      "Cores per node: 8\r\n",
      "CPU Utilized: 00:11:08\r\n",
      "CPU Efficiency: 62.31% of 00:17:52 core-walltime\r\n",
      "Job Wall-clock time: 00:02:14\r\n",
      "Memory Utilized: 8.80 MB\r\n",
      "Memory Efficiency: 0.43% of 2.00 GB\r\n"
     ]
    }
   ],
   "source": [
    "!seff 23347154"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can launch `makeCandidateRegions` on slurm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate $slurm_1_3\n",
    "#!/bin/sh\n",
    "# dependencies: python3 bioinfo/samtools-1.9 bioinfo/bedtools-2.27.1 bioinfo/tabix-0.2.5 bioinfo/juicer-1.5.6\n",
    "python {make_candidate_regions} \\\n",
    "--narrowPeak {peaks}{dnase_rep1}_{dnase_rep2}.macs2_peaks.narrowPeak.sorted \\\n",
    "--bam {dnase_dir}{dnase_rep1}_{dnase_rep2}.bam \\\n",
    "--outDir {peaks} \\\n",
    "--chrom_sizes {genome_file} \\\n",
    "--regions_blacklist {blacklist} \\\n",
    "--peakExtendFromSummit 250 \\\n",
    "--nStrongestPeaks 150000\n",
    "#Expected output: params.txt, foo1_foo2.macs2_peaks.narrowPeak.sorted.candidateRegions.bed, foo1_foo2.macs2_peaks.narrowPeak.sorted.foo1_foo2.bam.Counts.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING: depending on the length of the inputs, this script may be very RAM-demanding. So we recommend to allocate at least 16 GB RAM to avoid \"out of memory\" errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 23358051\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$work_dir\" \"$slurm_1_3\" \"$mail_user\"\n",
    "CONDA_BASE=$(conda info --base) && source $CONDA_BASE/etc/profile.d/conda.sh\n",
    "conda activate base && conda activate abcmodel\n",
    "module load bioinfo/samtools-1.9 bioinfo/bedtools-2.27.1 bioinfo/tabix-0.2.5 bioinfo/juicer-1.5.6\n",
    "sbatch --mem=64G --cpus-per-task=1 -J step1.3 --mail-user=$3 --mail-type=END,FAIL --workdir=$1 --export=ALL -p workq $2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: 23358051\r\n",
      "Cluster: genobull\r\n",
      "User/Group: thoellinger/U1220\r\n",
      "State: COMPLETED (exit code 0)\r\n",
      "Cores: 1\r\n",
      "CPU Utilized: 00:13:29\r\n",
      "CPU Efficiency: 99.63% of 00:13:32 core-walltime\r\n",
      "Job Wall-clock time: 00:13:32\r\n",
      "Memory Utilized: 18.79 GB\r\n",
      "Memory Efficiency: 29.36% of 64.00 GB\r\n"
     ]
    }
   ],
   "source": [
    "!seff 23358051"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that it did not result in the same number of candidate regions as in Fulco et al 's paper (not even close - 136,205 instead of 162,181)..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: quantifying enhancer activity\n",
    "\n",
    "#### Use ABC `run.neighborhoods.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate $slurm_2\n",
    "#!/bin/sh\n",
    "python {run_neighborhoods} \\\n",
    "--candidate_enhancer_regions {peaks}{dnase_rep1}_{dnase_rep2}.macs2_peaks.narrowPeak.sorted.candidateRegions.bed \\\n",
    "--genes {annotations_dir}gene_ids.bed \\\n",
    "--H3K27ac {h3k27_file_rep1},{h3k27_file_rep1} \\\n",
    "--DHS {dnase_file_rep1},{dnase_file_rep2} \\\n",
    "--expression_table {gene_expression_table}  \\\n",
    "--chrom_sizes {genome_file} \\\n",
    "--ubiquitously_expressed_genes {ubiquitously_expressed_genes} \\\n",
    "--cellType {cell_type} \\\n",
    "--outdir {neighborhoods}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING: depending on the length of the inputs, this script may be very RAM-demanding. So we recommend to allocate at least 32 GB RAM to avoid \"out of memory\" errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 23359930\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$work_dir\" \"$slurm_2\" \"$mail_user\"\n",
    "CONDA_BASE=$(conda info --base) && source $CONDA_BASE/etc/profile.d/conda.sh\n",
    "conda activate base && conda activate abcmodel\n",
    "module load bioinfo/samtools-1.9 bioinfo/bedtools-2.27.1 bioinfo/tabix-0.2.5 bioinfo/juicer-1.5.6\n",
    "sbatch --mem=32G --cpus-per-task=1 -J step2 --mail-user=$3 --mail-type=END,FAIL --workdir=$1 --export=ALL -p workq $2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: 23359930\r\n",
      "Cluster: genobull\r\n",
      "User/Group: thoellinger/U1220\r\n",
      "State: COMPLETED (exit code 0)\r\n",
      "Cores: 1\r\n",
      "CPU Utilized: 00:19:07\r\n",
      "CPU Efficiency: 99.83% of 00:19:09 core-walltime\r\n",
      "Job Wall-clock time: 00:19:09\r\n",
      "Memory Utilized: 2.76 GB\r\n",
      "Memory Efficiency: 8.62% of 32.00 GB\r\n"
     ]
    }
   ],
   "source": [
    "!seff 23359930"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: computing the ABC score\n",
    "\n",
    "If experimentally derived contact data is not available, one can run the ABC model using the powerlaw estimate only. In this case the ```--HiCdir``` argument should be excluded from ```predict.py``` and the ```--score_column powerlaw.Score``` argument should be included in ```predict.py```. In this case the ```ABC.Score``` column of the predictions file will be set to ```NaN```. The ```powerlaw.Score``` column of the output prediction files will be the relevant Score column to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate $slurm_3\n",
    "#!/bin/sh\n",
    "python {predict} \\\n",
    "--enhancers {neighborhoods}EnhancerList.txt \\\n",
    "--genes {neighborhoods}GeneList.txt \\\n",
    "--score_column powerlaw.Score \\\n",
    "--hic_resolution 5000 \\\n",
    "--scale_hic_using_powerlaw \\\n",
    "--threshold .02 \\\n",
    "--cellType {cell_type} \\\n",
    "--outdir {predictions} \\\n",
    "--make_all_putative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, that step is very RAM-demanding so we recommend to allocate at least 32G of RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 23361936\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$work_dir\" \"$slurm_3\" \"$mail_user\"\n",
    "CONDA_BASE=$(conda info --base) && source $CONDA_BASE/etc/profile.d/conda.sh\n",
    "conda activate base && conda activate abcmodel\n",
    "module load bioinfo/samtools-1.9 bioinfo/bedtools-2.27.1 bioinfo/tabix-0.2.5 bioinfo/juicer-1.5.6\n",
    "sbatch --mem=64G --cpus-per-task=1 -J step3 --mail-user=$3 --mail-type=END,FAIL --workdir=$1 --export=ALL -p workq $2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: 23361936\r\n",
      "Cluster: genobull\r\n",
      "User/Group: thoellinger/U1220\r\n",
      "State: COMPLETED (exit code 0)\r\n",
      "Cores: 1\r\n",
      "CPU Utilized: 00:24:13\r\n",
      "CPU Efficiency: 99.73% of 00:24:17 core-walltime\r\n",
      "Job Wall-clock time: 00:24:17\r\n",
      "Memory Utilized: 16.53 GB\r\n",
      "Memory Efficiency: 25.82% of 64.00 GB\r\n"
     ]
    }
   ],
   "source": [
    "!seff 23361936"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_non_expressed = predictions+\"EnhancerPredictionsAllPutativeNonExpressedGenes.txt\"\n",
    "predictions_expressed = predictions+\"EnhancerPredictionsAllPutative.txt\"\n",
    "all_predictions = predictions+\"AllPredictions.bedpe\" # does not exist yet\n",
    "all_predictions_sorted = all_predictions+\".sorted\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip ABC predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(predictions_non_expressed):\n",
    "    !gzip -cd $predictions_non_expressed\".gz\" > $predictions_non_expressed\n",
    "if not os.path.isfile(predictions_expressed):\n",
    "    !gzip -cd $predictions_expressed\".gz\" > $predictions_expressed    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge ABC predictions for expressed and non expressed genes, keep only columns of interest and sort the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$all_predictions\" \"$predictions_expressed\" \"$predictions_non_expressed\"\n",
    "if [[ ! -f $1 ]]\n",
    "then\n",
    "    awk '{print $1\"\\t\"$2\"\\t\"$3\"\\t\"$1\"\\t\"$10\"\\t\"$10\"\\t\"$9\"\\t\"$20\"\\t.\\t.\\t\"$13\"\\t\"$11}' $2 > $1;\n",
    "    tail -n+2 $3 | awk '{print $1\"\\t\"$2\"\\t\"$3\"\\t\"$1\"\\t\"$10\"\\t\"$10\"\\t\"$9\"\\t\"$20\"\\t.\\t.\\t\"$13\"\\t\"$11}' >> $1;\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is very RAM-demanding, we recommend using at least 64GB of ram to avoid \"out of memory\" errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/work2/project/regenet/workspace/thoellinger/ABC-Enhancer-Gene-Prediction/new_K562/ABC_output/Predictions/EnhancerPredictionsAllPutative.txt'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_expressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "srun: job 23362791 queued and waiting for resources\n",
      "srun: job 23362791 has been allocated resources\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$all_predictions\" \"$all_predictions_sorted\" \"$genome_file\"\n",
    "if [[ ! -f $V2 ]]\n",
    "then\n",
    "    export V1=$1 V2=$2 V3=$3\n",
    "    CONDA_BASE=$(conda info --base) && source $CONDA_BASE/etc/profile.d/conda.sh\n",
    "    conda activate base && conda activate abcmodel\n",
    "    module load bioinfo/bedtools-2.27.1\n",
    "    srun --mem=64G bash\n",
    "    tail -n+2 $V1 | bedtools sort -faidx $V3 -i stdin  > $V2\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intersection with Fulco et al 's CRISPRi-FlowFISH validation dataset\n",
    "\n",
    "Remark: this section is not strictly speaking included in the notebook ; I performed the computations \"by hand\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "conda activate base && module load bioinfo/bedtools-2.27.1 && srun --mem=64G --pty bash\n",
    "```\n",
    "\n",
    "> ```bash\n",
    "> wc -l /work2/project/regenet/workspace/thoellinger/CRISPRi_FlowFISH/k562/3863.fulco.bedpe.sorted\n",
    "> ```\n",
    ">\n",
    "> 3863\n",
    ">\n",
    "> ```bash\n",
    "> bedtools intersect -sorted -u -a /work2/project/regenet/workspace/thoellinger/CRISPRi_FlowFISH/k562/3863.fulco.bedpe.sorted -b ABC_output/Predictions/AllPredictions.bedpe.sorted -g reference/chr_sizes |wc -l\n",
    "> ```\n",
    ">\n",
    "> 3640\n",
    "\n",
    "Not perfect, but enough to continue.\n",
    "\n",
    "```bash\n",
    "bedtools intersect -sorted -wo -a ABC_output/Predictions/AllPredictions.bedpe.sorted -b /work2/project/regenet/workspace/thoellinger/CRISPRi_FlowFISH/k562/3863.fulco.bedpe.sorted -g reference/chr_sizes > ABC_output/Predictions/enhancer_predictions_intersected_with_CRISPRi_FlowFISH.bedpe\n",
    "```\n",
    "\n",
    "> ```bash\n",
    "> wc -l ABC_output/Predictions/enhancer_predictions_intersected_with_CRISPRi_FlowFISH.bedpe\n",
    "> ```\n",
    ">\n",
    "> 1597054\n",
    "\n",
    "When we keep only the lines for which the gene ids are the same, there are still > 3863 predictions. Actually, multiple candidates sometimes overlap the same validation element, resulting in multiple ABC scores for a single validation data.\n",
    "\n",
    "How to choose which ones to keep?\n",
    "\n",
    "#### First strategy: we keep the ones that maximize the ABC score\n",
    "\n",
    "> ```bash\n",
    "> awk 'BEGIN{FS=\"\\t\"} {if($7==$24){print $7, $24}}' ABC_output/Predictions/enhancer_predictions_intersected_with_CRISPRi_FlowFISH.bedpe |wc -l\n",
    "> ```\n",
    ">\n",
    "> 3768\n",
    "\n",
    "```bash\n",
    "awk 'BEGIN{FS=\"\\t\"; OFS=\"\\t\"} {if($7==$24){print $23, $13, $14, $15, $24, $8, $25}}' ABC_output/Predictions/enhancer_predictions_intersected_with_CRISPRi_FlowFISH.bedpe |awk 'BEGIN{FS=\"\\t\"; OFS=\"\\t\"} {uniq=$1\"\\t\"$2\"\\t\"$3\"\\t\"$4\"\\t\"$5; if($6>val[uniq]){val[uniq]=$6}} END{for(u in val){print u, val[u]}}' > ABC_output/Predictions/Predictions_over_CRISPRi_FlowFISH.bedpe\n",
    "```\n",
    "\n",
    "> ```bash\n",
    "> wc -l ABC_output/Predictions/Predictions_over_CRISPRi_FlowFISH.bedpe\n",
    "> ```\n",
    ">\n",
    "> 3640\n",
    "\n",
    "#### Second strategy: we keep the ones that maximize the overlap\n",
    "\n",
    "#### Third strategy: weighted average of the ABC scores, where weights are the sizes of the overlaps\n",
    "\n",
    "#### 4th strategy: weighted average of the ABC scores, where weights are the sizes of the overlaps, divided by the sizes of the predicted regions\n",
    "\n",
    "This one might be a little more complicated to implement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis with R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the 3640 predictions remaining with 1st strategy (out of 3863 contained in the validation dataset), 105 positives (among 109) remain. There are 128 `NA` values in the ABC scores, but none of them pertain to the 105 predictions for ground positives.\n",
    "\n",
    "### Analysis with R (results)\n",
    "\n",
    "![Image: Precision-Recall curve for the first strategy](max_abc_precision_recall_positives_105_negatives_3535_with_128_NA_negatives.png)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
